{"ast":null,"code":"var _jsxFileName = \"/Users/katherynrojas/Documents/reconocimiento-facial-react-node/frontend/src/FaceRecognition.js\",\n  _s = $RefreshSig$();\nimport React, { useEffect, useRef, useState } from 'react';\nimport * as faceapi from 'face-api.js';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst FaceRecognition = () => {\n  _s();\n  const [image, setImage] = useState(null); // Estado para la imagen cargada\n  const [detections, setDetections] = useState(null); // Estado para las detecciones faciales\n  const imageRef = useRef(null); // Referencia a la imagen cargada\n\n  // Cargar los modelos cuando el componente se monte\n  useEffect(() => {\n    const loadModels = async () => {\n      try {\n        // Cargar los modelos desde la carpeta /models\n        await faceapi.nets.ssdMobilenetv1.loadFromUri('/models');\n        await faceapi.nets.faceLandmark68Net.loadFromUri('/models');\n        await faceapi.nets.faceRecognitionNet.loadFromUri('/models');\n        console.log('Modelos cargados correctamente');\n      } catch (error) {\n        console.error('Error al cargar los modelos:', error);\n      }\n    };\n    loadModels();\n  }, []); // Se ejecuta solo una vez cuando el componente se monta\n\n  // Manejar la carga de la imagen y realizar detección facial\n  const handleImageUpload = async event => {\n    const file = event.target.files[0]; // Obtener el archivo de imagen\n    setImage(URL.createObjectURL(file)); // Mostrar la imagen seleccionada\n\n    // Esperar a que la imagen esté completamente cargada antes de detectar\n    if (imageRef.current) {\n      const imgElement = imageRef.current;\n      imgElement.onload = async () => {\n        try {\n          // Realizar la detección facial\n          const detections = await faceapi.detectAllFaces(imgElement).withFaceLandmarks().withFaceDescriptors();\n          setDetections(detections); // Guardar detecciones en el estado\n          console.log(detections); // Mostrar los resultados en la consola\n        } catch (error) {\n          console.error('Error durante la detección facial:', error);\n        }\n      };\n    }\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(\"h1\", {\n      children: \"Reconocimiento de Personas\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 53,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"input\", {\n      type: \"file\",\n      accept: \"image/*\",\n      onChange: handleImageUpload\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 54,\n      columnNumber: 7\n    }, this), \" \", image &&\n    /*#__PURE__*/\n    // Mostrar la imagen seleccionada si existe\n    _jsxDEV(\"img\", {\n      ref: imageRef,\n      src: image,\n      alt: \"Uploaded\",\n      style: {\n        width: '300px'\n      }\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 56,\n      columnNumber: 9\n    }, this), detections &&\n    /*#__PURE__*/\n    // Mostrar las detecciones si existen\n    _jsxDEV(\"div\", {\n      children: [/*#__PURE__*/_jsxDEV(\"h2\", {\n        children: \"Detecciones:\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 60,\n        columnNumber: 11\n      }, this), /*#__PURE__*/_jsxDEV(\"pre\", {\n        children: JSON.stringify(detections, null, 2)\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 61,\n        columnNumber: 11\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 59,\n      columnNumber: 9\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 52,\n    columnNumber: 5\n  }, this);\n};\n_s(FaceRecognition, \"spCFAAgC/+ug5VnYDROqSmjK6jY=\");\n_c = FaceRecognition;\nexport default FaceRecognition;\nvar _c;\n$RefreshReg$(_c, \"FaceRecognition\");","map":{"version":3,"names":["React","useEffect","useRef","useState","faceapi","jsxDEV","_jsxDEV","FaceRecognition","_s","image","setImage","detections","setDetections","imageRef","loadModels","nets","ssdMobilenetv1","loadFromUri","faceLandmark68Net","faceRecognitionNet","console","log","error","handleImageUpload","event","file","target","files","URL","createObjectURL","current","imgElement","onload","detectAllFaces","withFaceLandmarks","withFaceDescriptors","children","fileName","_jsxFileName","lineNumber","columnNumber","type","accept","onChange","ref","src","alt","style","width","JSON","stringify","_c","$RefreshReg$"],"sources":["/Users/katherynrojas/Documents/reconocimiento-facial-react-node/frontend/src/FaceRecognition.js"],"sourcesContent":["import React, { useEffect, useRef, useState } from 'react';\nimport * as faceapi from 'face-api.js';\n\nconst FaceRecognition = () => {\n  const [image, setImage] = useState(null); // Estado para la imagen cargada\n  const [detections, setDetections] = useState(null); // Estado para las detecciones faciales\n  const imageRef = useRef(null); // Referencia a la imagen cargada\n\n  // Cargar los modelos cuando el componente se monte\n  useEffect(() => {\n    const loadModels = async () => {\n      try {\n        // Cargar los modelos desde la carpeta /models\n        await faceapi.nets.ssdMobilenetv1.loadFromUri('/models');\n        await faceapi.nets.faceLandmark68Net.loadFromUri('/models');\n        await faceapi.nets.faceRecognitionNet.loadFromUri('/models');\n        console.log('Modelos cargados correctamente');\n      } catch (error) {\n        console.error('Error al cargar los modelos:', error);\n      }\n    };\n\n    loadModels();\n  }, []); // Se ejecuta solo una vez cuando el componente se monta\n\n  // Manejar la carga de la imagen y realizar detección facial\n  const handleImageUpload = async (event) => {\n    const file = event.target.files[0]; // Obtener el archivo de imagen\n    setImage(URL.createObjectURL(file)); // Mostrar la imagen seleccionada\n\n    // Esperar a que la imagen esté completamente cargada antes de detectar\n    if (imageRef.current) {\n      const imgElement = imageRef.current;\n\n      imgElement.onload = async () => {\n        try {\n          // Realizar la detección facial\n          const detections = await faceapi.detectAllFaces(imgElement)\n            .withFaceLandmarks()\n            .withFaceDescriptors();\n          \n          setDetections(detections); // Guardar detecciones en el estado\n          console.log(detections);  // Mostrar los resultados en la consola\n        } catch (error) {\n          console.error('Error durante la detección facial:', error);\n        }\n      };\n    }\n  };\n\n  return (\n    <div>\n      <h1>Reconocimiento de Personas</h1>\n      <input type=\"file\" accept=\"image/*\" onChange={handleImageUpload} /> {/* Input para cargar la imagen */}\n      {image && ( // Mostrar la imagen seleccionada si existe\n        <img ref={imageRef} src={image} alt=\"Uploaded\" style={{ width: '300px' }} />\n      )}\n      {detections && ( // Mostrar las detecciones si existen\n        <div>\n          <h2>Detecciones:</h2>\n          <pre>{JSON.stringify(detections, null, 2)}</pre>\n        </div>\n      )}\n    </div>\n  );\n};\n\nexport default FaceRecognition;\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,SAAS,EAAEC,MAAM,EAAEC,QAAQ,QAAQ,OAAO;AAC1D,OAAO,KAAKC,OAAO,MAAM,aAAa;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEvC,MAAMC,eAAe,GAAGA,CAAA,KAAM;EAAAC,EAAA;EAC5B,MAAM,CAACC,KAAK,EAAEC,QAAQ,CAAC,GAAGP,QAAQ,CAAC,IAAI,CAAC,CAAC,CAAC;EAC1C,MAAM,CAACQ,UAAU,EAAEC,aAAa,CAAC,GAAGT,QAAQ,CAAC,IAAI,CAAC,CAAC,CAAC;EACpD,MAAMU,QAAQ,GAAGX,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC;;EAE/B;EACAD,SAAS,CAAC,MAAM;IACd,MAAMa,UAAU,GAAG,MAAAA,CAAA,KAAY;MAC7B,IAAI;QACF;QACA,MAAMV,OAAO,CAACW,IAAI,CAACC,cAAc,CAACC,WAAW,CAAC,SAAS,CAAC;QACxD,MAAMb,OAAO,CAACW,IAAI,CAACG,iBAAiB,CAACD,WAAW,CAAC,SAAS,CAAC;QAC3D,MAAMb,OAAO,CAACW,IAAI,CAACI,kBAAkB,CAACF,WAAW,CAAC,SAAS,CAAC;QAC5DG,OAAO,CAACC,GAAG,CAAC,gCAAgC,CAAC;MAC/C,CAAC,CAAC,OAAOC,KAAK,EAAE;QACdF,OAAO,CAACE,KAAK,CAAC,8BAA8B,EAAEA,KAAK,CAAC;MACtD;IACF,CAAC;IAEDR,UAAU,CAAC,CAAC;EACd,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC;;EAER;EACA,MAAMS,iBAAiB,GAAG,MAAOC,KAAK,IAAK;IACzC,MAAMC,IAAI,GAAGD,KAAK,CAACE,MAAM,CAACC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;IACpCjB,QAAQ,CAACkB,GAAG,CAACC,eAAe,CAACJ,IAAI,CAAC,CAAC,CAAC,CAAC;;IAErC;IACA,IAAIZ,QAAQ,CAACiB,OAAO,EAAE;MACpB,MAAMC,UAAU,GAAGlB,QAAQ,CAACiB,OAAO;MAEnCC,UAAU,CAACC,MAAM,GAAG,YAAY;QAC9B,IAAI;UACF;UACA,MAAMrB,UAAU,GAAG,MAAMP,OAAO,CAAC6B,cAAc,CAACF,UAAU,CAAC,CACxDG,iBAAiB,CAAC,CAAC,CACnBC,mBAAmB,CAAC,CAAC;UAExBvB,aAAa,CAACD,UAAU,CAAC,CAAC,CAAC;UAC3BS,OAAO,CAACC,GAAG,CAACV,UAAU,CAAC,CAAC,CAAE;QAC5B,CAAC,CAAC,OAAOW,KAAK,EAAE;UACdF,OAAO,CAACE,KAAK,CAAC,oCAAoC,EAAEA,KAAK,CAAC;QAC5D;MACF,CAAC;IACH;EACF,CAAC;EAED,oBACEhB,OAAA;IAAA8B,QAAA,gBACE9B,OAAA;MAAA8B,QAAA,EAAI;IAA0B;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC,eACnClC,OAAA;MAAOmC,IAAI,EAAC,MAAM;MAACC,MAAM,EAAC,SAAS;MAACC,QAAQ,EAAEpB;IAAkB;MAAAc,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAE,CAAC,KAAC,EACnE/B,KAAK;IAAA;IAAM;IACVH,OAAA;MAAKsC,GAAG,EAAE/B,QAAS;MAACgC,GAAG,EAAEpC,KAAM;MAACqC,GAAG,EAAC,UAAU;MAACC,KAAK,EAAE;QAAEC,KAAK,EAAE;MAAQ;IAAE;MAAAX,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAE,CAC5E,EACA7B,UAAU;IAAA;IAAM;IACfL,OAAA;MAAA8B,QAAA,gBACE9B,OAAA;QAAA8B,QAAA,EAAI;MAAY;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC,eACrBlC,OAAA;QAAA8B,QAAA,EAAMa,IAAI,CAACC,SAAS,CAACvC,UAAU,EAAE,IAAI,EAAE,CAAC;MAAC;QAAA0B,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAM,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAC7C,CACN;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACE,CAAC;AAEV,CAAC;AAAChC,EAAA,CA9DID,eAAe;AAAA4C,EAAA,GAAf5C,eAAe;AAgErB,eAAeA,eAAe;AAAC,IAAA4C,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}