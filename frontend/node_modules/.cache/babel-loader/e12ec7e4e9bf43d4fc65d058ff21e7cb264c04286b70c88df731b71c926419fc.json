{"ast":null,"code":"var _jsxFileName = \"/Users/katherynrojas/Documents/reconocimiento-facial-react-node/frontend/src/VideoChat.js\",\n  _s = $RefreshSig$();\n/*import React, { useEffect, useRef, useState } from 'react';\nimport Peer from 'simple-peer';\nimport * as faceapi from 'face-api.js';\nimport io from 'socket.io-client';\n\n// const socket = io.connect('http://localhost:5000');\nconst socket = io.connect('https://glrtzw7g-5000.use2.devtunnels.ms'); // URL del backend\n\n\n\nconst VideoChat = () => {\n  const [stream, setStream] = useState(null);\n  const [me, setMe] = useState(\"\");\n  const [peer, setPeer] = useState(null);\n  const myVideoRef = useRef();\n  const userVideoRef = useRef();\n  const [detections, setDetections] = useState(null);\n  const [modelsLoaded, setModelsLoaded] = useState(false); // Estado para controlar la carga de modelos\n\n  // Cargar los modelos de face-api.js\n  const loadModels = async () => {\n    await faceapi.nets.tinyFaceDetector.loadFromUri('/models');\n    await faceapi.nets.faceLandmark68Net.loadFromUri('/models');\n    await faceapi.nets.faceRecognitionNet.loadFromUri('/models');\n    setModelsLoaded(true); // Cambiar el estado a true una vez que los modelos se hayan cargado\n    console.log('Modelos cargados');\n  };\n\n  useEffect(() => {\n    loadModels(); // Llama a loadModels al montar el componente\n\n    navigator.mediaDevices.getUserMedia({ video: true, audio: true }).then(stream => {\n      setStream(stream);\n      if (myVideoRef.current) {\n        myVideoRef.current.srcObject = stream;\n      }\n    });\n\n    socket.on('me', (id) => {\n      setMe(id);\n    });\n  }, []);\n\n  // Detectar rostros en tiempo real solo si los modelos están cargados\n  useEffect(() => {\n    const detectFaces = async () => {\n      if (myVideoRef.current && stream) {\n        const detections = await faceapi.detectAllFaces(\n          myVideoRef.current,\n          new faceapi.TinyFaceDetectorOptions()\n        ).withFaceLandmarks().withFaceDescriptors();\n        setDetections(detections);\n      }\n    };\n\n    const interval = setInterval(() => {\n      if (modelsLoaded) {\n        detectFaces(); // Ejecutar la detección solo si los modelos están cargados\n      }\n    }, 100);\n\n    return () => clearInterval(interval);\n  }, [stream, modelsLoaded]);\n\n  const startPeer = (initiator) => {\n    const newPeer = new Peer({ initiator, trickle: false, stream });\n\n    newPeer.on('signal', (data) => {\n      socket.emit('signal', { to: \"partner-id\", signal: data });\n    });\n\n    newPeer.on('stream', (userStream) => {\n      if (userVideoRef.current) {\n        userVideoRef.current.srcObject = userStream;\n      }\n    });\n\n    socket.on('signal', (signalData) => {\n      newPeer.signal(signalData.signal);\n    });\n\n    setPeer(newPeer);\n  };\n\n  return (\n    <div>\n      <h1>Video Chat con Reconocimiento Facial</h1>\n\n      <video ref={myVideoRef} autoPlay muted style={{ width: '300px' }} />\n      <video ref={userVideoRef} autoPlay style={{ width: '300px' }} />\n\n      <button onClick={() => startPeer(true)}>Iniciar llamada</button>\n      <button onClick={() => startPeer(false)}>Unirse a llamada</button>\n\n      {detections && (\n        <div>\n          <h2>Detecciones:</h2>\n          <pre>{JSON.stringify(detections, null, 2)}</pre>\n        </div>\n      )}\n    </div>\n  );\n};\n\nexport default VideoChat;*/\nimport React, { useEffect, useRef, useState } from 'react';\nimport io from 'socket.io-client';\n\n// Cambia aquí la URL al túnel correcto\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst socket = io('https://glrtzw7g-5000.use2.devtunnels.ms'); // Cambia esto al túnel de tu backend\n\nconst VideoChat = () => {\n  _s();\n  const [remoteStream, setRemoteStream] = useState(null);\n  const [recipientId, setRecipientId] = useState(null);\n  const localVideoRef = useRef(null);\n  const remoteVideoRef = useRef(null);\n  const peerConnection = useRef(new RTCPeerConnection({\n    iceServers: [{\n      urls: 'stun:stun.l.google.com:19302'\n    }]\n  }));\n  useEffect(() => {\n    navigator.mediaDevices.getUserMedia({\n      video: true,\n      audio: true\n    }).then(stream => {\n      localVideoRef.current.srcObject = stream;\n      stream.getTracks().forEach(track => {\n        peerConnection.current.addTrack(track, stream);\n      });\n    });\n    socket.on('callReceived', data => {\n      const {\n        from\n      } = data;\n      setRecipientId(from);\n      startCall(from);\n    });\n    socket.on('callOffer', async data => {\n      const {\n        offer,\n        from\n      } = data;\n      await peerConnection.current.setRemoteDescription(new RTCSessionDescription(offer));\n      const answer = await peerConnection.current.createAnswer();\n      await peerConnection.current.setLocalDescription(answer);\n      socket.emit('callAnswer', {\n        answer,\n        to: from\n      });\n    });\n    socket.on('callAnswer', async data => {\n      const {\n        answer\n      } = data;\n      await peerConnection.current.setRemoteDescription(new RTCSessionDescription(answer));\n    });\n    socket.on('iceCandidate', async data => {\n      const {\n        candidate\n      } = data;\n      await peerConnection.current.addIceCandidate(new RTCIceCandidate(candidate));\n    });\n    peerConnection.current.ontrack = event => {\n      setRemoteStream(event.streams[0]);\n      remoteVideoRef.current.srcObject = event.streams[0];\n    };\n    peerConnection.current.onicecandidate = event => {\n      if (event.candidate) {\n        socket.emit('iceCandidate', {\n          candidate: event.candidate,\n          to: recipientId\n        });\n      }\n    };\n    return () => {\n      socket.off('callReceived');\n      socket.off('callOffer');\n      socket.off('callAnswer');\n      socket.off('iceCandidate');\n    };\n  }, [recipientId]);\n  const startCall = async id => {\n    const offer = await peerConnection.current.createOffer();\n    await peerConnection.current.setLocalDescription(offer);\n    socket.emit('startCall', {\n      recipientId: id\n    });\n    socket.emit('callOffer', {\n      offer,\n      to: id\n    });\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(\"video\", {\n      ref: localVideoRef,\n      autoPlay: true,\n      muted: true,\n      style: {\n        width: '300px'\n      }\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 182,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"video\", {\n      ref: remoteVideoRef,\n      autoPlay: true,\n      style: {\n        width: '300px'\n      }\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 183,\n      columnNumber: 13\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 181,\n    columnNumber: 9\n  }, this);\n};\n_s(VideoChat, \"zAqM8nYTfYkZUW53kTTzkWrljZ8=\");\n_c = VideoChat;\nexport default VideoChat;\nvar _c;\n$RefreshReg$(_c, \"VideoChat\");","map":{"version":3,"names":["React","useEffect","useRef","useState","io","jsxDEV","_jsxDEV","socket","VideoChat","_s","remoteStream","setRemoteStream","recipientId","setRecipientId","localVideoRef","remoteVideoRef","peerConnection","RTCPeerConnection","iceServers","urls","navigator","mediaDevices","getUserMedia","video","audio","then","stream","current","srcObject","getTracks","forEach","track","addTrack","on","data","from","startCall","offer","setRemoteDescription","RTCSessionDescription","answer","createAnswer","setLocalDescription","emit","to","candidate","addIceCandidate","RTCIceCandidate","ontrack","event","streams","onicecandidate","off","id","createOffer","children","ref","autoPlay","muted","style","width","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["/Users/katherynrojas/Documents/reconocimiento-facial-react-node/frontend/src/VideoChat.js"],"sourcesContent":["/*import React, { useEffect, useRef, useState } from 'react';\nimport Peer from 'simple-peer';\nimport * as faceapi from 'face-api.js';\nimport io from 'socket.io-client';\n\n// const socket = io.connect('http://localhost:5000');\nconst socket = io.connect('https://glrtzw7g-5000.use2.devtunnels.ms'); // URL del backend\n\n\n\nconst VideoChat = () => {\n  const [stream, setStream] = useState(null);\n  const [me, setMe] = useState(\"\");\n  const [peer, setPeer] = useState(null);\n  const myVideoRef = useRef();\n  const userVideoRef = useRef();\n  const [detections, setDetections] = useState(null);\n  const [modelsLoaded, setModelsLoaded] = useState(false); // Estado para controlar la carga de modelos\n\n  // Cargar los modelos de face-api.js\n  const loadModels = async () => {\n    await faceapi.nets.tinyFaceDetector.loadFromUri('/models');\n    await faceapi.nets.faceLandmark68Net.loadFromUri('/models');\n    await faceapi.nets.faceRecognitionNet.loadFromUri('/models');\n    setModelsLoaded(true); // Cambiar el estado a true una vez que los modelos se hayan cargado\n    console.log('Modelos cargados');\n  };\n\n  useEffect(() => {\n    loadModels(); // Llama a loadModels al montar el componente\n\n    navigator.mediaDevices.getUserMedia({ video: true, audio: true }).then(stream => {\n      setStream(stream);\n      if (myVideoRef.current) {\n        myVideoRef.current.srcObject = stream;\n      }\n    });\n\n    socket.on('me', (id) => {\n      setMe(id);\n    });\n  }, []);\n\n  // Detectar rostros en tiempo real solo si los modelos están cargados\n  useEffect(() => {\n    const detectFaces = async () => {\n      if (myVideoRef.current && stream) {\n        const detections = await faceapi.detectAllFaces(\n          myVideoRef.current,\n          new faceapi.TinyFaceDetectorOptions()\n        ).withFaceLandmarks().withFaceDescriptors();\n        setDetections(detections);\n      }\n    };\n\n    const interval = setInterval(() => {\n      if (modelsLoaded) {\n        detectFaces(); // Ejecutar la detección solo si los modelos están cargados\n      }\n    }, 100);\n\n    return () => clearInterval(interval);\n  }, [stream, modelsLoaded]);\n\n  const startPeer = (initiator) => {\n    const newPeer = new Peer({ initiator, trickle: false, stream });\n\n    newPeer.on('signal', (data) => {\n      socket.emit('signal', { to: \"partner-id\", signal: data });\n    });\n\n    newPeer.on('stream', (userStream) => {\n      if (userVideoRef.current) {\n        userVideoRef.current.srcObject = userStream;\n      }\n    });\n\n    socket.on('signal', (signalData) => {\n      newPeer.signal(signalData.signal);\n    });\n\n    setPeer(newPeer);\n  };\n\n  return (\n    <div>\n      <h1>Video Chat con Reconocimiento Facial</h1>\n\n      <video ref={myVideoRef} autoPlay muted style={{ width: '300px' }} />\n      <video ref={userVideoRef} autoPlay style={{ width: '300px' }} />\n\n      <button onClick={() => startPeer(true)}>Iniciar llamada</button>\n      <button onClick={() => startPeer(false)}>Unirse a llamada</button>\n\n      {detections && (\n        <div>\n          <h2>Detecciones:</h2>\n          <pre>{JSON.stringify(detections, null, 2)}</pre>\n        </div>\n      )}\n    </div>\n  );\n};\n\nexport default VideoChat;*/\nimport React, { useEffect, useRef, useState } from 'react';\nimport io from 'socket.io-client';\n\n// Cambia aquí la URL al túnel correcto\nconst socket = io('https://glrtzw7g-5000.use2.devtunnels.ms'); // Cambia esto al túnel de tu backend\n\nconst VideoChat = () => {\n    const [remoteStream, setRemoteStream] = useState(null);\n    const [recipientId, setRecipientId] = useState(null);\n    const localVideoRef = useRef(null);\n    const remoteVideoRef = useRef(null);\n    const peerConnection = useRef(new RTCPeerConnection({\n        iceServers: [{ urls: 'stun:stun.l.google.com:19302' }]\n    }));\n\n    useEffect(() => {\n        navigator.mediaDevices.getUserMedia({ video: true, audio: true })\n            .then(stream => {\n                localVideoRef.current.srcObject = stream;\n                stream.getTracks().forEach(track => {\n                    peerConnection.current.addTrack(track, stream);\n                });\n            });\n\n        socket.on('callReceived', (data) => {\n            const { from } = data;\n            setRecipientId(from);\n            startCall(from);\n        });\n\n        socket.on('callOffer', async (data) => {\n            const { offer, from } = data;\n            await peerConnection.current.setRemoteDescription(new RTCSessionDescription(offer));\n            const answer = await peerConnection.current.createAnswer();\n            await peerConnection.current.setLocalDescription(answer);\n            socket.emit('callAnswer', { answer, to: from });\n        });\n\n        socket.on('callAnswer', async (data) => {\n            const { answer } = data;\n            await peerConnection.current.setRemoteDescription(new RTCSessionDescription(answer));\n        });\n\n        socket.on('iceCandidate', async (data) => {\n            const { candidate } = data;\n            await peerConnection.current.addIceCandidate(new RTCIceCandidate(candidate));\n        });\n\n        peerConnection.current.ontrack = (event) => {\n            setRemoteStream(event.streams[0]);\n            remoteVideoRef.current.srcObject = event.streams[0];\n        };\n\n        peerConnection.current.onicecandidate = (event) => {\n            if (event.candidate) {\n                socket.emit('iceCandidate', { candidate: event.candidate, to: recipientId });\n            }\n        };\n\n        return () => {\n            socket.off('callReceived');\n            socket.off('callOffer');\n            socket.off('callAnswer');\n            socket.off('iceCandidate');\n        };\n    }, [recipientId]);\n\n    const startCall = async (id) => {\n        const offer = await peerConnection.current.createOffer();\n        await peerConnection.current.setLocalDescription(offer);\n        socket.emit('startCall', { recipientId: id });\n        socket.emit('callOffer', { offer, to: id });\n    };\n\n    return (\n        <div>\n            <video ref={localVideoRef} autoPlay muted style={{ width: '300px' }} />\n            <video ref={remoteVideoRef} autoPlay style={{ width: '300px' }} />\n        </div>\n    );\n};\n\nexport default VideoChat;\n"],"mappings":";;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAOA,KAAK,IAAIC,SAAS,EAAEC,MAAM,EAAEC,QAAQ,QAAQ,OAAO;AAC1D,OAAOC,EAAE,MAAM,kBAAkB;;AAEjC;AAAA,SAAAC,MAAA,IAAAC,OAAA;AACA,MAAMC,MAAM,GAAGH,EAAE,CAAC,0CAA0C,CAAC,CAAC,CAAC;;AAE/D,MAAMI,SAAS,GAAGA,CAAA,KAAM;EAAAC,EAAA;EACpB,MAAM,CAACC,YAAY,EAAEC,eAAe,CAAC,GAAGR,QAAQ,CAAC,IAAI,CAAC;EACtD,MAAM,CAACS,WAAW,EAAEC,cAAc,CAAC,GAAGV,QAAQ,CAAC,IAAI,CAAC;EACpD,MAAMW,aAAa,GAAGZ,MAAM,CAAC,IAAI,CAAC;EAClC,MAAMa,cAAc,GAAGb,MAAM,CAAC,IAAI,CAAC;EACnC,MAAMc,cAAc,GAAGd,MAAM,CAAC,IAAIe,iBAAiB,CAAC;IAChDC,UAAU,EAAE,CAAC;MAAEC,IAAI,EAAE;IAA+B,CAAC;EACzD,CAAC,CAAC,CAAC;EAEHlB,SAAS,CAAC,MAAM;IACZmB,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;MAAEC,KAAK,EAAE,IAAI;MAAEC,KAAK,EAAE;IAAK,CAAC,CAAC,CAC5DC,IAAI,CAACC,MAAM,IAAI;MACZZ,aAAa,CAACa,OAAO,CAACC,SAAS,GAAGF,MAAM;MACxCA,MAAM,CAACG,SAAS,CAAC,CAAC,CAACC,OAAO,CAACC,KAAK,IAAI;QAChCf,cAAc,CAACW,OAAO,CAACK,QAAQ,CAACD,KAAK,EAAEL,MAAM,CAAC;MAClD,CAAC,CAAC;IACN,CAAC,CAAC;IAENnB,MAAM,CAAC0B,EAAE,CAAC,cAAc,EAAGC,IAAI,IAAK;MAChC,MAAM;QAAEC;MAAK,CAAC,GAAGD,IAAI;MACrBrB,cAAc,CAACsB,IAAI,CAAC;MACpBC,SAAS,CAACD,IAAI,CAAC;IACnB,CAAC,CAAC;IAEF5B,MAAM,CAAC0B,EAAE,CAAC,WAAW,EAAE,MAAOC,IAAI,IAAK;MACnC,MAAM;QAAEG,KAAK;QAAEF;MAAK,CAAC,GAAGD,IAAI;MAC5B,MAAMlB,cAAc,CAACW,OAAO,CAACW,oBAAoB,CAAC,IAAIC,qBAAqB,CAACF,KAAK,CAAC,CAAC;MACnF,MAAMG,MAAM,GAAG,MAAMxB,cAAc,CAACW,OAAO,CAACc,YAAY,CAAC,CAAC;MAC1D,MAAMzB,cAAc,CAACW,OAAO,CAACe,mBAAmB,CAACF,MAAM,CAAC;MACxDjC,MAAM,CAACoC,IAAI,CAAC,YAAY,EAAE;QAAEH,MAAM;QAAEI,EAAE,EAAET;MAAK,CAAC,CAAC;IACnD,CAAC,CAAC;IAEF5B,MAAM,CAAC0B,EAAE,CAAC,YAAY,EAAE,MAAOC,IAAI,IAAK;MACpC,MAAM;QAAEM;MAAO,CAAC,GAAGN,IAAI;MACvB,MAAMlB,cAAc,CAACW,OAAO,CAACW,oBAAoB,CAAC,IAAIC,qBAAqB,CAACC,MAAM,CAAC,CAAC;IACxF,CAAC,CAAC;IAEFjC,MAAM,CAAC0B,EAAE,CAAC,cAAc,EAAE,MAAOC,IAAI,IAAK;MACtC,MAAM;QAAEW;MAAU,CAAC,GAAGX,IAAI;MAC1B,MAAMlB,cAAc,CAACW,OAAO,CAACmB,eAAe,CAAC,IAAIC,eAAe,CAACF,SAAS,CAAC,CAAC;IAChF,CAAC,CAAC;IAEF7B,cAAc,CAACW,OAAO,CAACqB,OAAO,GAAIC,KAAK,IAAK;MACxCtC,eAAe,CAACsC,KAAK,CAACC,OAAO,CAAC,CAAC,CAAC,CAAC;MACjCnC,cAAc,CAACY,OAAO,CAACC,SAAS,GAAGqB,KAAK,CAACC,OAAO,CAAC,CAAC,CAAC;IACvD,CAAC;IAEDlC,cAAc,CAACW,OAAO,CAACwB,cAAc,GAAIF,KAAK,IAAK;MAC/C,IAAIA,KAAK,CAACJ,SAAS,EAAE;QACjBtC,MAAM,CAACoC,IAAI,CAAC,cAAc,EAAE;UAAEE,SAAS,EAAEI,KAAK,CAACJ,SAAS;UAAED,EAAE,EAAEhC;QAAY,CAAC,CAAC;MAChF;IACJ,CAAC;IAED,OAAO,MAAM;MACTL,MAAM,CAAC6C,GAAG,CAAC,cAAc,CAAC;MAC1B7C,MAAM,CAAC6C,GAAG,CAAC,WAAW,CAAC;MACvB7C,MAAM,CAAC6C,GAAG,CAAC,YAAY,CAAC;MACxB7C,MAAM,CAAC6C,GAAG,CAAC,cAAc,CAAC;IAC9B,CAAC;EACL,CAAC,EAAE,CAACxC,WAAW,CAAC,CAAC;EAEjB,MAAMwB,SAAS,GAAG,MAAOiB,EAAE,IAAK;IAC5B,MAAMhB,KAAK,GAAG,MAAMrB,cAAc,CAACW,OAAO,CAAC2B,WAAW,CAAC,CAAC;IACxD,MAAMtC,cAAc,CAACW,OAAO,CAACe,mBAAmB,CAACL,KAAK,CAAC;IACvD9B,MAAM,CAACoC,IAAI,CAAC,WAAW,EAAE;MAAE/B,WAAW,EAAEyC;IAAG,CAAC,CAAC;IAC7C9C,MAAM,CAACoC,IAAI,CAAC,WAAW,EAAE;MAAEN,KAAK;MAAEO,EAAE,EAAES;IAAG,CAAC,CAAC;EAC/C,CAAC;EAED,oBACI/C,OAAA;IAAAiD,QAAA,gBACIjD,OAAA;MAAOkD,GAAG,EAAE1C,aAAc;MAAC2C,QAAQ;MAACC,KAAK;MAACC,KAAK,EAAE;QAAEC,KAAK,EAAE;MAAQ;IAAE;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAE,CAAC,eACvE1D,OAAA;MAAOkD,GAAG,EAAEzC,cAAe;MAAC0C,QAAQ;MAACE,KAAK,EAAE;QAAEC,KAAK,EAAE;MAAQ;IAAE;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAE,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACjE,CAAC;AAEd,CAAC;AAACvD,EAAA,CA1EID,SAAS;AAAAyD,EAAA,GAATzD,SAAS;AA4Ef,eAAeA,SAAS;AAAC,IAAAyD,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}