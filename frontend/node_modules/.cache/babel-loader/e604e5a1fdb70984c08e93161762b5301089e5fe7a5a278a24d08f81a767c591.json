{"ast":null,"code":"import React,{useEffect,useRef,useState}from'react';import*as faceapi from'face-api.js';import{jsx as _jsx,jsxs as _jsxs}from\"react/jsx-runtime\";const FaceRecognition=()=>{const[image,setImage]=useState(null);// Estado para la imagen cargada\nconst[detections,setDetections]=useState(null);// Estado para las detecciones faciales\nconst imageRef=useRef(null);// Referencia a la imagen cargada\n// Cargar los modelos cuando el componente se monte\nuseEffect(()=>{const loadModels=async()=>{try{// Cargar los modelos desde la carpeta /models\nawait faceapi.nets.ssdMobilenetv1.loadFromUri('/models');await faceapi.nets.faceLandmark68Net.loadFromUri('/models');await faceapi.nets.faceRecognitionNet.loadFromUri('/models');console.log('Modelos cargados correctamente');}catch(error){console.error('Error al cargar los modelos:',error);}};loadModels();},[]);// Se ejecuta solo una vez cuando el componente se monta\n// Manejar la carga de la imagen y realizar detección facial\nconst handleImageUpload=async event=>{const file=event.target.files[0];// Obtener el archivo de imagen\nsetImage(URL.createObjectURL(file));// Mostrar la imagen seleccionada\n// Esperar a que la imagen esté completamente cargada antes de detectar\nif(imageRef.current){const imgElement=imageRef.current;imgElement.onload=async()=>{try{// Realizar la detección facial\nconst detections=await faceapi.detectAllFaces(imgElement).withFaceLandmarks().withFaceDescriptors();setDetections(detections);// Guardar detecciones en el estado\nconsole.log(detections);// Mostrar los resultados en la consola\n}catch(error){console.error('Error durante la detección facial:',error);}};}};return/*#__PURE__*/_jsxs(\"div\",{children:[/*#__PURE__*/_jsx(\"h1\",{children:\"Reconocimiento de Personas\"}),/*#__PURE__*/_jsx(\"input\",{type:\"file\",accept:\"image/*\",onChange:handleImageUpload}),\" \",image&&/*#__PURE__*/// Mostrar la imagen seleccionada si existe\n_jsx(\"img\",{ref:imageRef,src:image,alt:\"Uploaded\",style:{width:'300px'}}),detections&&/*#__PURE__*/// Mostrar las detecciones si existen\n_jsxs(\"div\",{children:[/*#__PURE__*/_jsx(\"h2\",{children:\"Detecciones:\"}),/*#__PURE__*/_jsx(\"pre\",{children:JSON.stringify(detections,null,2)})]})]});};export default FaceRecognition;","map":{"version":3,"names":["React","useEffect","useRef","useState","faceapi","jsx","_jsx","jsxs","_jsxs","FaceRecognition","image","setImage","detections","setDetections","imageRef","loadModels","nets","ssdMobilenetv1","loadFromUri","faceLandmark68Net","faceRecognitionNet","console","log","error","handleImageUpload","event","file","target","files","URL","createObjectURL","current","imgElement","onload","detectAllFaces","withFaceLandmarks","withFaceDescriptors","children","type","accept","onChange","ref","src","alt","style","width","JSON","stringify"],"sources":["/Users/katherynrojas/Documents/reconocimiento-facial-react-node/frontend/src/FaceRecognition.js"],"sourcesContent":["import React, { useEffect, useRef, useState } from 'react';\nimport * as faceapi from 'face-api.js';\n\nconst FaceRecognition = () => {\n  const [image, setImage] = useState(null); // Estado para la imagen cargada\n  const [detections, setDetections] = useState(null); // Estado para las detecciones faciales\n  const imageRef = useRef(null); // Referencia a la imagen cargada\n\n  // Cargar los modelos cuando el componente se monte\n  useEffect(() => {\n    const loadModels = async () => {\n      try {\n        // Cargar los modelos desde la carpeta /models\n        await faceapi.nets.ssdMobilenetv1.loadFromUri('/models');\n        await faceapi.nets.faceLandmark68Net.loadFromUri('/models');\n        await faceapi.nets.faceRecognitionNet.loadFromUri('/models');\n        console.log('Modelos cargados correctamente');\n      } catch (error) {\n        console.error('Error al cargar los modelos:', error);\n      }\n    };\n\n    loadModels();\n  }, []); // Se ejecuta solo una vez cuando el componente se monta\n\n  // Manejar la carga de la imagen y realizar detección facial\n  const handleImageUpload = async (event) => {\n    const file = event.target.files[0]; // Obtener el archivo de imagen\n    setImage(URL.createObjectURL(file)); // Mostrar la imagen seleccionada\n\n    // Esperar a que la imagen esté completamente cargada antes de detectar\n    if (imageRef.current) {\n      const imgElement = imageRef.current;\n\n      imgElement.onload = async () => {\n        try {\n          // Realizar la detección facial\n          const detections = await faceapi.detectAllFaces(imgElement)\n            .withFaceLandmarks()\n            .withFaceDescriptors();\n          \n          setDetections(detections); // Guardar detecciones en el estado\n          console.log(detections);  // Mostrar los resultados en la consola\n        } catch (error) {\n          console.error('Error durante la detección facial:', error);\n        }\n      };\n    }\n  };\n\n  return (\n    <div>\n      <h1>Reconocimiento de Personas</h1>\n      <input type=\"file\" accept=\"image/*\" onChange={handleImageUpload} /> {/* Input para cargar la imagen */}\n      {image && ( // Mostrar la imagen seleccionada si existe\n        <img ref={imageRef} src={image} alt=\"Uploaded\" style={{ width: '300px' }} />\n      )}\n      {detections && ( // Mostrar las detecciones si existen\n        <div>\n          <h2>Detecciones:</h2>\n          <pre>{JSON.stringify(detections, null, 2)}</pre>\n        </div>\n      )}\n    </div>\n  );\n};\n\nexport default FaceRecognition;\n"],"mappings":"AAAA,MAAO,CAAAA,KAAK,EAAIC,SAAS,CAAEC,MAAM,CAAEC,QAAQ,KAAQ,OAAO,CAC1D,MAAO,GAAK,CAAAC,OAAO,KAAM,aAAa,CAAC,OAAAC,GAAA,IAAAC,IAAA,CAAAC,IAAA,IAAAC,KAAA,yBAEvC,KAAM,CAAAC,eAAe,CAAGA,CAAA,GAAM,CAC5B,KAAM,CAACC,KAAK,CAAEC,QAAQ,CAAC,CAAGR,QAAQ,CAAC,IAAI,CAAC,CAAE;AAC1C,KAAM,CAACS,UAAU,CAAEC,aAAa,CAAC,CAAGV,QAAQ,CAAC,IAAI,CAAC,CAAE;AACpD,KAAM,CAAAW,QAAQ,CAAGZ,MAAM,CAAC,IAAI,CAAC,CAAE;AAE/B;AACAD,SAAS,CAAC,IAAM,CACd,KAAM,CAAAc,UAAU,CAAG,KAAAA,CAAA,GAAY,CAC7B,GAAI,CACF;AACA,KAAM,CAAAX,OAAO,CAACY,IAAI,CAACC,cAAc,CAACC,WAAW,CAAC,SAAS,CAAC,CACxD,KAAM,CAAAd,OAAO,CAACY,IAAI,CAACG,iBAAiB,CAACD,WAAW,CAAC,SAAS,CAAC,CAC3D,KAAM,CAAAd,OAAO,CAACY,IAAI,CAACI,kBAAkB,CAACF,WAAW,CAAC,SAAS,CAAC,CAC5DG,OAAO,CAACC,GAAG,CAAC,gCAAgC,CAAC,CAC/C,CAAE,MAAOC,KAAK,CAAE,CACdF,OAAO,CAACE,KAAK,CAAC,8BAA8B,CAAEA,KAAK,CAAC,CACtD,CACF,CAAC,CAEDR,UAAU,CAAC,CAAC,CACd,CAAC,CAAE,EAAE,CAAC,CAAE;AAER;AACA,KAAM,CAAAS,iBAAiB,CAAG,KAAO,CAAAC,KAAK,EAAK,CACzC,KAAM,CAAAC,IAAI,CAAGD,KAAK,CAACE,MAAM,CAACC,KAAK,CAAC,CAAC,CAAC,CAAE;AACpCjB,QAAQ,CAACkB,GAAG,CAACC,eAAe,CAACJ,IAAI,CAAC,CAAC,CAAE;AAErC;AACA,GAAIZ,QAAQ,CAACiB,OAAO,CAAE,CACpB,KAAM,CAAAC,UAAU,CAAGlB,QAAQ,CAACiB,OAAO,CAEnCC,UAAU,CAACC,MAAM,CAAG,SAAY,CAC9B,GAAI,CACF;AACA,KAAM,CAAArB,UAAU,CAAG,KAAM,CAAAR,OAAO,CAAC8B,cAAc,CAACF,UAAU,CAAC,CACxDG,iBAAiB,CAAC,CAAC,CACnBC,mBAAmB,CAAC,CAAC,CAExBvB,aAAa,CAACD,UAAU,CAAC,CAAE;AAC3BS,OAAO,CAACC,GAAG,CAACV,UAAU,CAAC,CAAG;AAC5B,CAAE,MAAOW,KAAK,CAAE,CACdF,OAAO,CAACE,KAAK,CAAC,oCAAoC,CAAEA,KAAK,CAAC,CAC5D,CACF,CAAC,CACH,CACF,CAAC,CAED,mBACEf,KAAA,QAAA6B,QAAA,eACE/B,IAAA,OAAA+B,QAAA,CAAI,4BAA0B,CAAI,CAAC,cACnC/B,IAAA,UAAOgC,IAAI,CAAC,MAAM,CAACC,MAAM,CAAC,SAAS,CAACC,QAAQ,CAAEhB,iBAAkB,CAAE,CAAC,IAAC,CACnEd,KAAK,eAAM;AACVJ,IAAA,QAAKmC,GAAG,CAAE3B,QAAS,CAAC4B,GAAG,CAAEhC,KAAM,CAACiC,GAAG,CAAC,UAAU,CAACC,KAAK,CAAE,CAAEC,KAAK,CAAE,OAAQ,CAAE,CAAE,CAC5E,CACAjC,UAAU,eAAM;AACfJ,KAAA,QAAA6B,QAAA,eACE/B,IAAA,OAAA+B,QAAA,CAAI,cAAY,CAAI,CAAC,cACrB/B,IAAA,QAAA+B,QAAA,CAAMS,IAAI,CAACC,SAAS,CAACnC,UAAU,CAAE,IAAI,CAAE,CAAC,CAAC,CAAM,CAAC,EAC7C,CACN,EACE,CAAC,CAEV,CAAC,CAED,cAAe,CAAAH,eAAe","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}